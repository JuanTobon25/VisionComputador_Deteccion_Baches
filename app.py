import streamlit as st
import os
import zipfile
import io
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import kaggle
import tempfile

# -------------------------------------------------------
# âš™ï¸ CONFIGURACIÃ“N DE LA APP
# -------------------------------------------------------
st.set_page_config(page_title="Clasificador de Baches", page_icon="ğŸ•³ï¸", layout="centered")

st.title("ğŸ•³ï¸ Clasificador de Baches con IA")
st.write("Sube una imagen y el modelo la clasificarÃ¡ automÃ¡ticamente como **Con bache** o **Sin bache**.")

# -------------------------------------------------------
# âš™ï¸ AUTENTICACIÃ“N CON KAGGLE DESDE st.secrets
# -------------------------------------------------------
try:
    os.environ["KAGGLE_USERNAME"] = st.secrets["KAGGLE_USERNAME"]
    os.environ["KAGGLE_KEY"] = st.secrets["KAGGLE_KEY"]
    st.success("ğŸ” AutenticaciÃ³n con Kaggle configurada correctamente.")
except Exception as e:
    st.error(f"âš ï¸ No se encontraron las credenciales de Kaggle en `st.secrets`: {e}")
    st.stop()

# -------------------------------------------------------
# âš™ï¸ DESCARGA DEL MODELO DESDE KAGGLE
# -------------------------------------------------------
DATASET_NAME = "juanjostobnvargas/cnn-baches"

with tempfile.TemporaryDirectory() as tmp_dir:
    st.info("ğŸ“¦ Descargando modelo desde Kaggle...")
    os.system(f"kaggle datasets download -d {DATASET_NAME} -p {tmp_dir}")

    # Buscar el zip descargado y extraerlo
    for file in os.listdir(tmp_dir):
        if file.endswith(".zip"):
            with zipfile.ZipFile(os.path.join(tmp_dir, file), "r") as zip_ref:
                zip_ref.extractall(tmp_dir)
            os.remove(os.path.join(tmp_dir, file))

    # Localizar el archivo del modelo
    model_path = None
    for root, _, files in os.walk(tmp_dir):
        for f in files:
            if f.endswith(".h5"):
                model_path = os.path.join(root, f)
                break

    if not model_path:
        st.error("âŒ No se encontrÃ³ el archivo del modelo en el dataset.")
        st.stop()

    # -------------------------------------------------------
    # âš™ï¸ CARGA DEL MODELO
    # -------------------------------------------------------
    try:
        model = load_model(model_path)
        st.success("âœ… Modelo cargado correctamente.")
    except Exception as e:
        st.error(f"âŒ Error al cargar el modelo: {e}")
        st.stop()

# -------------------------------------------------------
# ğŸ§© SUBIDA DE IMAGEN
# -------------------------------------------------------
uploaded_file = st.file_uploader("ğŸ“¸ Sube una imagen", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    try:
        # Cargar y procesar la imagen a (128,128)
        img = image.load_img(io.BytesIO(uploaded_file.read()), target_size=(128, 128))
        img_array = np.expand_dims(image.img_to_array(img) / 255.0, axis=0)

        # Mostrar imagen centrada
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.image(img, caption="ğŸ–¼ï¸ Imagen cargada", width=220)

        # -------------------------------------------------------
        # ğŸ§  PREDICCIÃ“N
        # -------------------------------------------------------
        with st.spinner("ğŸ” Clasificando..."):
            pred = model.predict(img_array)[0][0]

        # -------------------------------------------------------
        # ğŸ“Š RESULTADO
        # -------------------------------------------------------
        st.subheader("ğŸ“Š Resultado de la PredicciÃ³n")
        if pred > 0.5:
            st.success(f"ğŸš§ **Con bache** (confianza: {pred:.2f})")
        else:
            st.info(f"ğŸ›£ï¸ **Sin bache** (confianza: {1 - pred:.2f})")

    except Exception as e:
        st.error(f"âš ï¸ Error procesando la imagen: {e}")

